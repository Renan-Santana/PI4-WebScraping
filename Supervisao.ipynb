{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando biblioteca Pandas para a criação e manipulação de DataFrames.\n",
    "import pandas as pd\n",
    "\n",
    "# Importando o Numpy.\n",
    "import numpy as np\n",
    "\n",
    "# Importando o método PLT para visualizar graficamente os dados, cálculos e regressões que aplicarmos.\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Importando modelos para a realização dos testes de treino.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Importando métricas de avaliações para os modelos.\n",
    "from sklearn.metrics import confusion_matrix, f1_score, auc, roc_auc_score, roc_curve\n",
    "\n",
    "# Importando o método de validação cruzada K-Fold, pontuação do modelo e o separador de dados para treino e teste.\n",
    "from sklearn.model_selection import KFold, cross_val_score,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização TF:\n",
    "dados_treino_tf = pd.read_csv(\"tweets_vetorizados_tf_agrupados.csv\", sep = \",\", header = None)\n",
    "dados_treino_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_tf.columns = [dados_treino_tf.loc[0]]\n",
    "dados_treino_tf = dados_treino_tf.drop(dados_treino_tf.index [[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização IDF:\n",
    "dados_treino_idf = pd.read_csv(\"tweets_vetorizados_idf_agrupados.csv\", sep = \",\", header = None)\n",
    "dados_treino_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_idf.columns = [dados_treino_idf.loc[0]]\n",
    "dados_treino_idf = dados_treino_idf.drop(dados_treino_idf.index [[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando dataset de dados de treino da vetorização TF_IDF:\n",
    "dados_treino_tf_idf = pd.read_csv(\"tweets_vetorizados_tf_idf_agrupados.csv\", sep = \",\", header = None)\n",
    "dados_treino_tf_idf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados:\n",
    "dados_treino_tf_idf.columns = [dados_treino_tf_idf.loc[0]]\n",
    "dados_treino_tf_idf = dados_treino_tf_idf.drop(dados_treino_tf_idf.index [[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Regressão Logística (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_preditoras = dados_treino_tf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "modelo_tf = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "modelo_tf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "predicao_regressao_logistica = modelo_tf.predict(variaveis_preditoras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_tf = cross_val_score(modelo_tf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_tf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_tf))\n",
    "print('\\nPredições feitas:\\n', predicao_regressao_logistica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_tf = confusion_matrix(variavel_predicao, modelo_tf.predict(variaveis_preditoras))\n",
    "matriz_confusao_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_tf[0, 0] / sum(matriz_confusao_tf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_tf[0, 0] / sum(matriz_confusao_tf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_tf[1, 1] / sum(matriz_confusao_tf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_tf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_tf.predict(variaveis_preditoras), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino_idf = dados_treino_idf.replace(np.nan, 0)\n",
    "\n",
    "variaveis_preditoras = dados_treino_idf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "modelo_idf = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "modelo_idf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "lr_pred = modelo_idf.predict(variaveis_preditoras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_idf = cross_val_score(modelo_idf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_idf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_idf))\n",
    "print('\\nPredições feitas:\\n', predicao_regressao_logistica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_idf = confusion_matrix(variavel_predicao, modelo_idf.predict(variaveis_preditoras))\n",
    "matriz_confusao_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_idf[0, 0] / sum(matriz_confusao_idf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_idf[0, 0] / sum(matriz_confusao_idf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_idf[1, 1] / sum(matriz_confusao_idf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis_preditoras = dados_treino_tf_idf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "\n",
    "# Criação e treino do modelo de Regressão Logística:\n",
    "modelo_tf_idf = LogisticRegression(penalty = 'l2', C = 1e42, solver = 'liblinear')\n",
    "modelo_tf_idf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "lr_pred = modelo_tf_idf.predict(variaveis_preditoras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_tf_idf = cross_val_score(modelo_idf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_tf_idf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_tf_idf))\n",
    "print('\\nPredições feitas:\\n', predicao_regressao_logistica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_tf_idf = confusion_matrix(variavel_predicao, modelo_idf.predict(variaveis_preditoras))\n",
    "matriz_confusao_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_tf_idf[0, 0] / sum(matriz_confusao_tf_idf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_tf_idf[0, 0] / sum(matriz_confusao_tf_idf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_tf_idf[1, 1] / sum(matriz_confusao_tf_idf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados para teste e treino:\n",
    "variaveis_preditoras = dados_treino_tf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo Naive Bayes:\n",
    "modelo_tf = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "modelo_tf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "predicao_naive_bayes = modelo_tf.predict(variaveis_preditoras)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_tf = cross_val_score(modelo_idf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_tf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_tf))\n",
    "print('\\nPredições feitas:\\n', predicao_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_tf = confusion_matrix(variavel_predicao, modelo_idf.predict(variaveis_preditoras))\n",
    "matriz_confusao_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_tf[0, 0] / sum(matriz_confusao_tf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_tf[0, 0] / sum(matriz_confusao_tf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_tf[1, 1] / sum(matriz_confusao_tf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino_idf = dados_treino_idf.replace(np.nan, 0)\n",
    "\n",
    "# Separação dos dados para teste e treino:\n",
    "variaveis_preditoras = dados_treino_idf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "\n",
    "# Criação e treino do modelo Naive Bayes:\n",
    "modelo_idf = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "modelo_idf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "predicao_naive_bayes = modelo_idf.predict(variaveis_preditoras)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_idf = cross_val_score(modelo_idf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_idf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_idf))\n",
    "print('\\nPredições feitas:\\n', predicao_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_idf = confusion_matrix(variavel_predicao, modelo_idf.predict(variaveis_preditoras))\n",
    "matriz_confusao_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_idf[0, 0] / sum(matriz_confusao_idf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_idf[0, 0] / sum(matriz_confusao_idf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_idf[1, 1] / sum(matriz_confusao_idf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dos dados para teste e treino:\n",
    "variaveis_preditoras = dados_treino_tf_idf.drop(['Cluster'], axis=1).values\n",
    "variavel_predicao = dados_treino_tf['Cluster'].values\n",
    "variaveis_preditoras_treino, variaveis_preditoras_teste, variavel_predicao_treino, variavel_predicao_teste = train_test_split(variaveis_preditoras, variavel_predicao, test_size = 0.3, random_state = 4)\n",
    "\n",
    "# Criação e treino do modelo Naive Bayes:\n",
    "modelo_tf_idf = MultinomialNB(alpha=0.01, fit_prior=True)\n",
    "modelo_tf_idf.fit(variaveis_preditoras_treino, variavel_predicao_treino)\n",
    "predicao_naive_bayes = modelo_tf_idf.predict(variaveis_preditoras)\n",
    "\n",
    "# Aplicação da validação cruzada K-Fold:\n",
    "validacao_kfold = KFold(10)\n",
    "resultado_tf_idf = cross_val_score(modelo_idf, variaveis_preditoras_teste, variavel_predicao_teste, cv = validacao_kfold)\n",
    "\n",
    "# Exibição dos resultados da validação:\n",
    "print('Resultados do modelo:\\n', resultado_tf_idf)\n",
    "print('\\nMédia dos resultados:', np.mean(resultado_tf_idf))\n",
    "print('\\nPredições feitas:\\n', predicao_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da matriz de confusão:\n",
    "print('Matriz de confusão:')\n",
    "matriz_confusao_tf_idf = confusion_matrix(variavel_predicao, modelo_idf.predict(variaveis_preditoras))\n",
    "matriz_confusao_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibição das métricas de avaliação do modelo:\n",
    "print('Revocação (Recall): ', matriz_confusao_tf_idf[0, 0] / sum(matriz_confusao_tf_idf[0, :]), '\\n')\n",
    "\n",
    "print('Precisão (Precision): ', matriz_confusao_tf_idf[0, 0] / sum(matriz_confusao_tf_idf[:, 0]), '\\n')\n",
    "\n",
    "print('Especificidade (Specificity): ', matriz_confusao_tf_idf[1, 1] / sum(matriz_confusao_tf_idf[1, :]), '\\n')\n",
    "\n",
    "print('F1 Macro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='macro'), '\\n')\n",
    "\n",
    "print('F1 Micro: ', f1_score(variavel_predicao, modelo_idf.predict(variaveis_preditoras), average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04eeb17173dda19b79ef31ce2f9124539f6d3d7f6428065f88e9861f21898bc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
